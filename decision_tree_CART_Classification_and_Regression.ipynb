{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "    \"\"\"树节点\"\"\"\n",
    "    def __init__(self, feature_idx = None, feature_val = None, node_val = None, left_child = None, right_child = None):\n",
    "        \"\"\"\n",
    "        feature_idx: 划分特征的索引\n",
    "        feature_val: 划分特征对应的值\n",
    "        node_val: 叶节点所存储的值，只有叶节点才能存储类别,分类树存储次数出现最多的类别，回归树存储节点的平均值\n",
    "        left_child: 左子树\n",
    "        right_child: 右子树\n",
    "        \"\"\"\n",
    "        self._feature_idx = feature_idx\n",
    "        self._feature_val = feature_val\n",
    "        self._node_val = node_val\n",
    "        self._left_child = left_child\n",
    "        self._right_child = right_child\n",
    "        \n",
    "class CART(object):\n",
    "    def __init__(self, min_sample = 2, min_gain = 1e-6, max_depth = np.inf):\n",
    "        \"\"\"\n",
    "        min_sample: 当某个节点的样本数小于min_sample将不再划分\n",
    "        min_gain: 如果划分后的增益不超过min_gain将不再划分，\n",
    "        对于分类树指的是基尼系数是否有足够的下降，\n",
    "        对于回归树指的是平方误差是否有足够的下降\n",
    "        max_depth: 指的是树的最大深度\n",
    "        \"\"\"\n",
    "        self._root = None\n",
    "        self._min_sample = min_sample\n",
    "        self._min_gain = min_gain\n",
    "        self._max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"模型训练过程就是树建立的过程\"\"\"\n",
    "        self._root = self._build_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"给定样本，预测类别或输出平均值\"\"\"\n",
    "        return self._predict(X, self._root)\n",
    "    \n",
    "    def _build_tree(self, X, y, cur_depth = 0):\n",
    "        \"\"\"构建树\"\"\"\n",
    "        # cur_depth 表示当前树的高度\n",
    "        # 如果子树只剩下一个类别则直接记为子节点,分类树是投票最多的类别，回归树是平均值        \n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            node_val = self._calc_node_val(y)\n",
    "            return TreeNode(node_val = node_val)\n",
    "        \n",
    "        before_divide = self._calc_evaluation(y) # 计算划分前的基尼指数或平方差\n",
    "        min_evaluation = np.inf # 划分后基尼指数或平方差的最小值\n",
    "        best_feature_idx = None # 最佳划分特征索引\n",
    "        best_feature_val = None # 最佳划分特征的值\n",
    "        \n",
    "        n_sample, n_feature = X.shape\n",
    "        # 当样本数大于等于某一阈值，并且当前树的深度小于等于最大深度时才能继续划分\n",
    "        if n_sample >= self._min_sample and cur_depth <= self._max_depth:\n",
    "            for i in range(n_feature):  # 依次遍历每个特征\n",
    "                feature_value = np.unique(X[:, i])\n",
    "                for fea_val in feature_value: # 遍历这个特征每个可能的取值\n",
    "                    X_left = X[X[:, i] <= fea_val]\n",
    "                    y_left = y[X[:, i] <= fea_val]\n",
    "                    \n",
    "                    X_right = X[X[:, i] > fea_val]\n",
    "                    y_right = y[X[:, i] > fea_val]\n",
    "                    \n",
    "                    if X_left.shape[0] > 0 and y_left.shape[0] > 0 and X_right.shape[0] > 0 and y_right.shape[0] > 0:\n",
    "                        after_divide = self._calc_division(y_left, y_right)\n",
    "                        if after_divide < min_evaluation:\n",
    "                            min_evaluation = after_divide\n",
    "                            best_feature_idx = i\n",
    "                            best_feature_val = fea_val\n",
    "        \n",
    "        # 如果划分前和划分后的基尼指数或平方差有足够的下降才能继续划分\n",
    "        if before_divide - min_evaluation > self._min_gain:\n",
    "            X_left = X[X[:, best_feature_idx] <= best_feature_val]\n",
    "            y_left = y[X[:, best_feature_idx] <= best_feature_val]\n",
    "            \n",
    "            X_right = X[X[:, best_feature_idx] > best_feature_val]\n",
    "            y_right = y[X[:, best_feature_idx] > best_feature_val]\n",
    "            \n",
    "            left_child = self._build_tree(X_left, y_left, cur_depth + 1) # 递归构建左子树\n",
    "            right_child = self._build_tree(X_right, y_right, cur_depth + 1) # 递归构建右子树\n",
    "            \n",
    "            return TreeNode(feature_idx = best_feature_idx, feature_val = best_feature_val, left_child = left_child, right_child = right_child)\n",
    "        \n",
    "        # 当样本数小于某一阈值，当前树的深度大于最大深度时, 或者未找到合适的划分时则看成子节点\n",
    "        node_val = self._calc_node_val(y)\n",
    "        return TreeNode(node_val = node_val)\n",
    "        \n",
    "    def _predict(self, X, tree = None):\n",
    "        \"\"\"给定输入来预测输出\"\"\"\n",
    "        if tree is None:\n",
    "            tree = self._root\n",
    "        \n",
    "        if tree._node_val is not None:\n",
    "            return tree._node_val\n",
    "        \n",
    "        feature_val = X[tree._feature_idx]\n",
    "        if feature_val <= tree._feature_val:\n",
    "            return self._predict(X, tree._left_child)\n",
    "        return self._predict(X, tree._right_child)\n",
    "    \n",
    "    def _calc_division(self, y_left, y_right):\n",
    "        \"\"\"计算划分后的基尼指数或平方差\"\"\"\n",
    "        return NotImplementedError\n",
    "    \n",
    "    def _calc_evaluation(self, y):\n",
    "        \"\"\"计算数据集的基尼指数或平方差\"\"\"\n",
    "        return NotImplementedError\n",
    "        \n",
    "    def _calc_node_val(self, y):\n",
    "        \"\"\"计算叶节点的值，分类树和回归树分别实现\"\"\"\n",
    "        return NotImplementedError()\n",
    "    \n",
    "class CARTClassification(CART):\n",
    "    def _calc_division(self, y_left, y_right):\n",
    "        \"\"\"计算划分后的基尼指数\"\"\"\n",
    "        left_evaluation = self._calc_evaluation(y_left)\n",
    "        right_evaluation = self._calc_evaluation(y_right)\n",
    "        p_left = y_left.shape[0] / (y_left.shape[0] + y_right.shape[0])\n",
    "        p_right = y_right.shape[0] / (y_left.shape[0] + y_right.shape[0])\n",
    "        after_divide = p_left * left_evaluation + p_right * right_evaluation\n",
    "        return after_divide\n",
    "    \n",
    "    def _calc_evaluation(self, y):\n",
    "        \"\"\"计算数据集的基尼指数\"\"\"\n",
    "        _, num = np.unique(y, return_counts = True)\n",
    "        gini = 1\n",
    "        for n in num:\n",
    "            gini -= (n / y.shape[0]) ** 2        \n",
    "        return gini\n",
    "        \n",
    "    def _calc_node_val(self, y):\n",
    "        \"\"\"计算叶节点的值，分类树从标签中进行投票，出现次数最多的是叶节点的类别\"\"\"\n",
    "        label, num_label = np.unique(y, return_counts = True)        \n",
    "        return label[np.argmax(num_label)]\n",
    "    \n",
    "class CARTRegression(CART):\n",
    "    def _calc_division(self, y_left, y_right):\n",
    "        \"\"\"计算划分后的平方差\"\"\"\n",
    "        left_evaluation = self._calc_evaluation(y_left)\n",
    "        right_evaluation = self._calc_evaluation(y_right)\n",
    "        after_divide = left_evaluation + right_evaluation\n",
    "        return after_divide\n",
    "    \n",
    "    def _calc_evaluation(self, y):\n",
    "        \"\"\"计算数据集的平方差\"\"\"    \n",
    "        return np.sum(np.power(y - np.mean(y), 2))\n",
    "        \n",
    "    def _calc_node_val(self, y):\n",
    "        \"\"\"计算叶节点的值，回归树将标签的平均值作为叶节点的预测值\"\"\"        \n",
    "        return np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART分类树在测试集上的准确率为：96.66666666666667%\n",
      "sklearn分类模型在测试集上准确率为：96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# CART分类树效果\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data, iris_y = load_iris(return_X_y=True) #return_X_y为True，表示因变量和自变量独立导出\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(iris_data, iris_y, train_size=0.8, shuffle=True)\n",
    "\n",
    "min_sample = 2\n",
    "max_depth = 20\n",
    "min_gain = 1e-6\n",
    "model = CARTClassification(min_sample, min_gain, max_depth)\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "n_test = xtest.shape[0]\n",
    "n_right = 0\n",
    "for i in range(n_test):\n",
    "    y_pred = model.predict(xtest[i])\n",
    "    if y_pred == ytest[i]:\n",
    "        n_right += 1\n",
    "print(\"CART分类树在测试集上的准确率为：{}%\".format((n_right * 100) / n_test))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "skmodel = DecisionTreeClassifier()\n",
    "skmodel.fit(xtrain, ytrain)\n",
    "print(\"sklearn分类模型在测试集上准确率为：{}%\".format(100 * skmodel.score(xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART回归树模型平均预测误差为：2.7\n",
      "skmodel回归模型平均预测误差为：2.8\n"
     ]
    }
   ],
   "source": [
    "# CART回归树效果\n",
    "from sklearn.datasets import load_boston\n",
    "boston_data, boston_y = load_boston(return_X_y=True)\n",
    "boston_xtrain, boston_xtest, boston_ytrain, boston_ytest = train_test_split(boston_data, boston_y, train_size=0.8, shuffle=True)\n",
    "\n",
    "min_sample = 2\n",
    "max_depth = 20\n",
    "min_gain = 1e-6\n",
    "regressor_model = CARTRegression(min_sample, min_gain, max_depth)\n",
    "regressor_model.fit(boston_xtrain, boston_ytrain)\n",
    "\n",
    "n_boston_test = boston_xtest.shape[0]\n",
    "diff = 0\n",
    "for i in range(n_boston_test):\n",
    "    boston_y_pred = regressor_model.predict(boston_xtest[i])\n",
    "    diff += abs(boston_y_pred - boston_ytest[i])\n",
    "    \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "boston_skmodel = DecisionTreeRegressor()\n",
    "boston_skmodel.fit(boston_xtrain, boston_ytrain)\n",
    "y_skpred = boston_skmodel.predict(boston_xtest)\n",
    "\n",
    "sk_diff = 0\n",
    "for i in range(n_boston_test):\n",
    "    sk_diff += abs(y_skpred[i] - boston_ytest[i])\n",
    "\n",
    "print(\"CART回归树模型平均预测误差为：{:.1f}\".format(diff / n_boston_test))\n",
    "print(\"skmodel回归模型平均预测误差为：{:.1f}\".format(sk_diff / n_boston_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
