{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "    \"\"\"树节点\"\"\"\n",
    "    def __init__(self, feature_idx = None, feature_val = None, feature_name = None, node_val = None, child = None):\n",
    "        \"\"\"\n",
    "        feature_idx: 划分特征的索引\n",
    "        feature_val: 划分特征对应的值\n",
    "        feature_name: 划分特征名\n",
    "        node_val: 叶节点所存储的值，只有叶节点才能存储类别\n",
    "        child: 子树,非叶节点存储划分信息\n",
    "        \"\"\"\n",
    "        self._feature_idx = feature_idx\n",
    "        self._feature_val = feature_val\n",
    "        self._feature_name = feature_name\n",
    "        self._node_val = node_val\n",
    "        self._child = child\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, feature_name, etype = \"gain\", epsilon = 0.01):\n",
    "        \"\"\"\n",
    "        feature: 表示每列特证名\n",
    "        etype: 其中“gain”为信息增益，\"ratio\"为信息增益比\n",
    "        epsilon: 当信息增益或信息增益比小于某一阈值时，直接把该节点看成叶节点\n",
    "        \"\"\"\n",
    "        self._root = None\n",
    "        self._fea_name = feature_name\n",
    "        self._etype = etype\n",
    "        self._epsilon = epsilon\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"模型训练\"\"\"\n",
    "        self._root = self._build_tree(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"模型预测\"\"\"\n",
    "        return self._predict(X, self._root)\n",
    "        \n",
    "    def _build_tree(self, X, y):\n",
    "        \"\"\"构建树的过程就是训练的过程\"\"\"\n",
    "        # 只剩下一个特证时投票判断类别\n",
    "        if X.shape[1] == 1:\n",
    "            node_val = self._vote_label(y)\n",
    "            return TreeNode(node_val = node_val)\n",
    "        \n",
    "        # 子树只剩下一个类别时就是叶节点所属类别\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return TreeNode(node_val = y[0])\n",
    "        \n",
    "        n_feature = X.shape[1]\n",
    "        max_gain = -np.inf\n",
    "        max_fea_idx = 0 # 信息增益或信息增益比最大所对应的特征索引\n",
    "        for i in range(n_feature):\n",
    "            if self._etype == \"gain\":\n",
    "                gain = self._calc_gain(X[:, i], y)\n",
    "            else:\n",
    "                gain = self._calc_gain_ration(X[:, i], y)\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                max_fea_idx = i\n",
    "                \n",
    "        # 如果该特征的信息增益或信息增益比太小则不进行划分,直接是叶节点\n",
    "        if max_gain < self._epsilon:\n",
    "            node_val = self._vote_label(y)\n",
    "            return TreeNode(node_val = node_val)\n",
    "        \n",
    "        #找到划分的特征\n",
    "        feature_name = self._fea_name[max_fea_idx]\n",
    "        child_tree = dict() # 使用字典树来存储{key(特征每一个可能的值)， value(根据此特征构建子树)}\n",
    "        feature_val = np.unique(X[:, max_fea_idx]) #查看划分特征每一个可能的值\n",
    "        for fea_val in feature_val:\n",
    "            child_X = X[X[:, max_fea_idx] == fea_val]\n",
    "            child_y = y[X[:, max_fea_idx] == fea_val]\n",
    "            child_X = np.delete(child_X, max_fea_idx, 1)\n",
    "            child_tree[fea_val] = self._build_tree(child_X, child_y) #构建子树\n",
    "        return TreeNode(max_fea_idx, feature_name = feature_name, child = child_tree) \n",
    "            \n",
    "    def _predict(self, X, tree = None):\n",
    "        \"\"\"预测的过程就是输入给定样本后，将其划分到所属的叶节点\"\"\"\n",
    "        if tree is None:\n",
    "            tree = self._root\n",
    "        \n",
    "        if tree._node_val is not None:\n",
    "            return tree._node_val\n",
    "        \n",
    "        fea_idx = tree._feature_idx\n",
    "        for fea_val, child_node in tree._child.items():\n",
    "            if X[fea_idx] == fea_val:\n",
    "                # 若是叶节点则直接返回类别\n",
    "                if child_node._node_val is not None:\n",
    "                    return child_node._node_val\n",
    "                else:\n",
    "                    #否则去子树中找\n",
    "                    return self._predict(X, child_node)                \n",
    "                      \n",
    "    def _vote_label(self, y):\n",
    "        \"\"\"统计y中出现次数最多的类别\"\"\"\n",
    "        label, num_label = np.unique(y, return_counts = True)\n",
    "        return label[np.argmax(num_label)]\n",
    "    \n",
    "    def _calc_entropy(slef, y):\n",
    "        \"\"\"计算熵\"\"\"\n",
    "        entropy = 0\n",
    "        _, numc = np.unique(y, return_counts = True)\n",
    "        for n in numc:\n",
    "            p = n / y.shape[0]\n",
    "            entropy -= p * np.log2(p)\n",
    "        return entropy\n",
    "    \n",
    "    def _calc_condition_entropy(self, X, y):\n",
    "        \"\"\"计算条件熵\"\"\"\n",
    "        cond_entropy = 0\n",
    "        # 特征X可能的取值以及对应的次数\n",
    "        xval, num_x = np.unique(X, return_counts = True)\n",
    "        \n",
    "        for v,n in zip(xval, num_x):\n",
    "            y_sub = y[X == v]\n",
    "            sub_entropy = self._calc_entropy(y_sub)\n",
    "            p = n / y.shape[0]\n",
    "            cond_entropy += p * sub_entropy\n",
    "        return cond_entropy          \n",
    "        \n",
    "    def _calc_gain(self, X, y):\n",
    "        \"\"\"计算信息增益\"\"\"\n",
    "        return self._calc_entropy(y) - self._calc_condition_entropy(X, y)        \n",
    "        \n",
    "    def _calc_gain_ration(self, X, y):\n",
    "        \"\"\"计算信息增益比\"\"\"\n",
    "        return self._calc_gain(X, y) / self._calc_entropy(X)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树（ID3/C4.5）在训练集上的准确率为：100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "xtrain, _, ytrain, _ = train_test_split(iris.data, iris.target, train_size=0.8, shuffle=True)\n",
    "feature_name = iris.feature_names\n",
    "etype =  \"gain\" \n",
    "epsilon = 0.01\n",
    "\n",
    "model = DecisionTree(feature_name, etype, epsilon)\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "n_train = xtrain.shape[0]\n",
    "n_right = 0\n",
    "for i in range(n_train):\n",
    "    y_pred = model.predict(xtrain[i])\n",
    "    if y_pred == ytrain[i]:\n",
    "        n_right += 1\n",
    "print(\"决策树（ID3/C4.5）在训练集上的准确率为：{}%\".format((n_right * 100) / n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
