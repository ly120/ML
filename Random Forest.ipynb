{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import seed, randrange, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest():\n",
    "    def __init__(self, max_depth = None, min_size = None, sample_size = None, n_trees = None, n_features = None):\n",
    "        \"\"\"\n",
    "            max_depth   决策树的最大深度\n",
    "            min_size    叶子结点的大小\n",
    "            sample_size 训练数据集的样本采样比例\n",
    "            n_trees     决策树的个数\n",
    "            n_features  选取特征的个数\n",
    "        \"\"\"     \n",
    "        self._trees = None\n",
    "        self._max_depth = max_depth\n",
    "        self._min_size = min_size\n",
    "        self._sample_size = sample_size\n",
    "        self._n_trees = n_trees\n",
    "        self._n_features = n_features\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._trees = list()\n",
    "        for i in range(self._n_trees):  #以sample_size的比例对数据进行采样，并构建每一颗决策树\n",
    "            sample_X, sample_y = self.subsample(X, y, self._sample_size)\n",
    "            tree = self.build_tree(sample_X, sample_y, max_depth, min_size, n_features)\n",
    "            self._trees.append(tree)        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        #对于每一个测试样本，bagging预测后的结果是\n",
    "        return self.bagging_predict(X, self._trees)\n",
    "        \n",
    "    def subsample(self, X, y, ratio):\n",
    "        \"\"\"有放回的重采样\"\"\"\n",
    "        sample_X = list()\n",
    "        sample_y = list()\n",
    "        n_sample = round(len(X) * ratio)\n",
    "        while len(sample_X) < n_sample:\n",
    "            index = randrange(len(X))\n",
    "            sample_X.append(X[index])\n",
    "            sample_y.append(y[index])\n",
    "        return sample_X, sample_y   \n",
    "\n",
    "    def test_split(self, index, value, X, y):\n",
    "        left_X, left_y, right_X, right_y = list(), list(), list(), list()  # left和right中存储的是y值\n",
    "        for idx in range(len(X)):\n",
    "            if X[idx][index] <= value:\n",
    "                left_X.append(X[idx])\n",
    "                left_y.append(y[idx])\n",
    "            else:\n",
    "                right_X.append(X[idx])\n",
    "                right_y.append(y[idx])\n",
    "        return left_X, left_y, right_X, right_y\n",
    "    \n",
    "    def gini_index(self, groups, class_val):\n",
    "        gini = 0\n",
    "        D = len(groups[1]) + len(groups[3])\n",
    "        for i in range(2):\n",
    "            sub_gini = 1.0\n",
    "            size = len(groups[i * 2 + 1])\n",
    "            for cls in class_val:    \n",
    "                if size == 0: continue\n",
    "                p = groups[i * 2 + 1].count(cls) / float(size)\n",
    "                sub_gini -= p ** 2\n",
    "            gini += len(groups[i * 2 + 1]) / D * sub_gini\n",
    "        return gini     \n",
    "    \n",
    "    def get_split(self, X, y, n_features):\n",
    "        \"\"\"找出分割数据集的最优特征index，最优特征值each[index以及分割完后的数据groups(left_X, left_y, right_X, right_y)\"\"\"\n",
    "        class_val = list(set(y)) #list(set(each[-1] for each in train))\n",
    "        b_index, b_value, b_score, b_groups = 100000, 100000, 100000, None\n",
    "        features = list()\n",
    "        while len(features) < n_features:  #有放回的重采样特征\n",
    "            index = randrange(len(X[0])) # randrange(10)表示从0都9中选\n",
    "            if index not in features:\n",
    "                features.append(index)\n",
    "        for index in features:\n",
    "            for idx in range(len(X)):\n",
    "                # 遍历每一个index索引下的每一个训练样本可能value值来作为分类值，找出最优的分类特征和特征值\n",
    "                groups = self.test_split(index, X[idx][index], X, y)\n",
    "                gini = self.gini_index(groups, class_val)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, X[idx][index], gini, groups\n",
    "        return {'index': b_index, 'value': b_value, 'groups': b_groups}    \n",
    "\n",
    "    def to_leaf(self, y):\n",
    "        return max(set(y), key = y.count) # 在max函数中，以key的函数对象为判断标准（key相当于属性），这里是输出次数（属性）最大的标签\n",
    "\n",
    "    def split(self, node, max_depth, min_size, n_features, depth):\n",
    "        left_X, left_y, right_X, right_y = node['groups']\n",
    "        del(node['groups'])\n",
    "\n",
    "        if not left_y or not right_y:\n",
    "            node['left'] = node['right'] = self.to_leaf(left_y + right_y)\n",
    "            return\n",
    "                              \n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_leaf(left_y), self.to_leaf(right_y)\n",
    "            return\n",
    "\n",
    "        if len(left_y) <= min_size:\n",
    "            node['left'] = self.to_leaf(left_y)\n",
    "        else:\n",
    "            node['left'] = self.get_split(left_X, left_y, n_features)  # node['left']是一个多层字典的形式\n",
    "            self.split(node['left'], max_depth, min_size, n_features, depth+1)\n",
    "\n",
    "        if len(right_y) <= min_size:\n",
    "            node['right'] = self.to_leaf(right_y)\n",
    "        else:\n",
    "            node['right'] = self.get_split(right_X, right_y, n_features)  # node['right']是一个多层字典的形式\n",
    "            self.split(node['right'], max_depth, min_size, n_features, depth+1)   \n",
    "    \n",
    "    def build_tree(self, X, y, max_depth, min_size, n_features):\n",
    "        \"\"\"创建一颗决策树\n",
    "        输入：\n",
    "            X, y：     训练集数据和标签\n",
    "            max_depth:  最大深度\n",
    "            min_size:   叶子结点的大小\n",
    "            n_features: 选取特征的个数\n",
    "        输出：\n",
    "            root:       返回一颗决策树\n",
    "        \"\"\"\n",
    "        root = self.get_split(X, y, n_features) # 找到这颗决策树分割的最优特征和最优特征值\n",
    "        self.split(root, max_depth, min_size, n_features, 1) # 然后递归处理这颗决策树\n",
    "        return root    \n",
    "    \n",
    "    def pred(self, node, X):\n",
    "        \"\"\"预测一个测试样本在决策树上所属类别\"\"\"\n",
    "        if X[node['index']] <= node['value']:\n",
    "            if isinstance(node['left'], dict): # isinstance判断该对象是否已知\n",
    "                return self.pred(node['left'], X)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict): # isinstance判断该对象是否已知\n",
    "                return self.pred(node['right'], X)\n",
    "            else:\n",
    "                return node['right']\n",
    "\n",
    "    def bagging_predict(self, X, trees = None):\n",
    "        \"\"\"\n",
    "        输入:\n",
    "            trees: 树的集合\n",
    "            each:  测试数据集的每一行数据\n",
    "        输出：\n",
    "            投票法得到所属类别        \n",
    "        \"\"\"\n",
    "        if trees == None:\n",
    "            trees = self._trees\n",
    "        preds = [self.pred(tree, X) for tree in trees]\n",
    "        return max(set(preds), key = preds.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林在测试集上的准确率为：93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data, iris_y = load_iris(return_X_y=True) #return_X_y为True，表示因变量和自变量独立导出\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(iris_data, iris_y, train_size=0.8, shuffle=True)\n",
    "\n",
    "max_depth = 3\n",
    "min_size = 2      \n",
    "sample_size = 1.0 \n",
    "n_trees = 200\n",
    "n_features = int(np.sqrt(len(iris_data[0])))\n",
    "model = Random_Forest(max_depth, min_size, sample_size, n_trees, n_features)\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "n_test = xtest.shape[0]\n",
    "n_right = 0\n",
    "for i in range(n_test):\n",
    "    y_pred = model.predict(xtest[i])\n",
    "    if y_pred == ytest[i]:\n",
    "        n_right += 1\n",
    "print(\"随机森林在测试集上的准确率为：{}%\".format((n_right * 100) / n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn随机森林分类模型在测试集上准确率为：93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=n_trees, max_depth=max_depth, min_samples_split=min_size, max_features = n_features, bootstrap=True, criterion='gini')\n",
    "clf.fit(xtrain, ytrain)\n",
    "print(\"sklearn随机森林分类模型在测试集上准确率为：{}%\".format(100 * clf.score(xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
